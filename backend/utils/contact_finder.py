from bs4 import BeautifulSoup
from selenium.webdriver.common.by import By
from urllib.parse import urljoin
import time
import logging
import requests

# ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ç¦æ­¢ãƒ¯ãƒ¼ãƒ‰
SCRAPING_DISALLOW = ["User-agent: * Disallow: /"]

# å–¶æ¥­åˆ©ç”¨ç¦æ­¢ãƒ¯ãƒ¼ãƒ‰
SALES_DISALLOW_WORDS = ["å–¶æ¥­", "ã‚»ãƒ¼ãƒ«ã‚¹", "ãŠæ–­ã‚Š", "é æ…®", "å•†ç”¨ç›®çš„", "å‹§èª˜", "ç§ã¯ãƒ­ãƒœãƒƒãƒˆã§ã¯ã‚ã‚Šã¾ã›ã‚“"]

def check_scraping_allowed(base_url):
    """ã‚µã‚¤ãƒˆã® `robots.txt` ã‚’ãƒã‚§ãƒƒã‚¯ã—ã€ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ãŒè¨±å¯ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª"""
    try:
        robots_url = urljoin(base_url, "/robots.txt")
        response = requests.get(robots_url, timeout=5)

        if response.status_code == 200:
            robots_content = response.text.lower()
            for rule in SCRAPING_DISALLOW:
                if rule.lower() in robots_content:
                    logging.info(f"ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°NG: {base_url}")
                    return False
        return True
    except Exception as e:
        logging.warning(f"robots.txt ãƒã‚§ãƒƒã‚¯å¤±æ•— ({base_url}): {e}")
        return True  # `robots.txt` ãŒå–å¾—ã§ããªã‹ã£ãŸå ´åˆã¯ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°å¯èƒ½ã¨åˆ¤æ–­

def contains_sales_restrictions(driver):
    """å•ã„åˆã‚ã›ãƒšãƒ¼ã‚¸ã«å–¶æ¥­åˆ©ç”¨ç¦æ­¢ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª"""
    page_text = driver.page_source.lower()
    return any(word in page_text for word in SALES_DISALLOW_WORDS)

def find_contact_page(driver, base_url):
    """å•ã„åˆã‚ã›ãƒšãƒ¼ã‚¸ã‚’æ¤œç´¢ã™ã‚‹"""
    logging.info(f"å•ã„åˆã‚ã›ãƒšãƒ¼ã‚¸æ¤œç´¢é–‹å§‹: {base_url}")

    if not check_scraping_allowed(base_url):
        logging.info(f"ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°NG: {base_url}")
        return {"status": "error", "message": "ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°NG"}

    try:
        driver.get(base_url)
        time.sleep(5)

        soup = BeautifulSoup(driver.page_source, 'html.parser')

        # 1. ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸å†…ã«ãƒ•ã‚©ãƒ¼ãƒ ãŒã‚ã‚‹ã‹ç¢ºèª
        if is_valid_contact_page(driver):
            logging.info(f"å•ã„åˆã‚ã›ãƒ•ã‚©ãƒ¼ãƒ ã‚’ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã§ç™ºè¦‹: {base_url}")
            return {"status": "success", "contact_page": base_url}

        # 2. ã€ŒãŠå•ã„åˆã‚ã›ã€ã‚„ã€Œcontactã€ã®ãƒªãƒ³ã‚¯ã‚’æ¢ã—ã¦é·ç§»
        keywords = ["ãŠå•ã„åˆã‚ã›", "ãŠå•åˆã›", "ã‚³ãƒ³ã‚¿ã‚¯ãƒˆ", "contact", "inquiry", "support"]
        links = soup.find_all("a", href=True)

        for link in links:
            link_text = link.get_text(strip=True).lower()
            href = link["href"]

            if any(keyword in link_text for keyword in keywords) or any(keyword in href.lower() for keyword in keywords):
                contact_page = urljoin(base_url.rstrip("/"), href.lstrip("/"))
                logging.info(f"å•ã„åˆã‚ã›ãƒšãƒ¼ã‚¸å€™è£œ: {contact_page}")

                driver.get(contact_page)
                time.sleep(3)

                if is_valid_contact_page(driver):
                    # é€ä»˜ä¸å¯ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
                    if contains_sales_restrictions(driver):
                        logging.info(f"é€ä»˜ä¸å¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º: {contact_page}")
                        return {"status": "error", "message": "é€ä»˜ä¸å¯ï¼ˆå–¶æ¥­åˆ©ç”¨ç¦æ­¢ï¼‰"}

                    logging.info(f"å•ã„åˆã‚ã›ãƒšãƒ¼ã‚¸ç¢ºå®š: {contact_page}")
                    return {"status": "success", "contact_page": contact_page}

    except Exception as e:
        logging.error(f"å•ã„åˆã‚ã›ãƒšãƒ¼ã‚¸æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

    logging.info(f"å•ã„åˆã‚ã›ãƒšãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ: {base_url}")
    return {"status": "error", "message": "å•ã„åˆã‚ã›ãƒšãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ"}

def is_valid_contact_page(driver):
    """å•ã„åˆã‚ã›ãƒšãƒ¼ã‚¸ã¨ã—ã¦é©åˆ‡ã‹ã‚’åˆ¤å®š"""
    try:
        soup = BeautifulSoup(driver.page_source, 'html.parser')
        meta_desc = soup.find("meta", {"name": "description"})
        meta_content = meta_desc["content"].lower() if meta_desc else ""

        # å•ã„åˆã‚ã›ãƒšãƒ¼ã‚¸ã¨ã—ã¦è€ƒãˆã‚‰ã‚Œã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆå‚è€ƒç¨‹åº¦ï¼‰
        valid_keywords = ["ãŠå•ã„åˆã‚ã›", "ãŠå•åˆã›", "ã‚³ãƒ³ã‚¿ã‚¯ãƒˆ", "contact", "inquiry", "support", "customer service"]

        # ãƒšãƒ¼ã‚¸å†…ã®ãƒ•ã‚©ãƒ¼ãƒ ã‚’å–å¾—
        forms = driver.find_elements(By.TAG_NAME, "form")
        input_fields = driver.find_elements(By.TAG_NAME, "input")
        textareas = driver.find_elements(By.TAG_NAME, "textarea")

        # ğŸ”¹ ã€ä¿®æ­£ãƒã‚¤ãƒ³ãƒˆã€‘ãƒ•ã‚©ãƒ¼ãƒ ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’æœ€å„ªå…ˆæ¡ä»¶ã«ã™ã‚‹
        has_form = len(forms) > 0

        # ğŸ”¹ ã€ä¿®æ­£ãƒã‚¤ãƒ³ãƒˆã€‘å•ã„åˆã‚ã›ãƒ•ã‚©ãƒ¼ãƒ ã‚‰ã—ã„å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒã‚ã‚‹ã‹ã‚’é‡è¦–
        has_email_field = any("email" in field.get_attribute("name").lower() for field in input_fields)
        has_textarea = len(textareas) > 0

        # ğŸ”¹ ã€ä¿®æ­£ãƒã‚¤ãƒ³ãƒˆã€‘URLã«ã‚‚ç€ç›®ã™ã‚‹
        contact_url_keywords = ["contact", "inquiry", "support", "customer"]
        has_contact_url = any(keyword in driver.current_url.lower() for keyword in contact_url_keywords)

        # ğŸ”¹ ã€ä¿®æ­£ãƒã‚¤ãƒ³ãƒˆã€‘ã‚¿ã‚¤ãƒˆãƒ«ã‚„ãƒ¡ã‚¿æƒ…å ±ã®å½±éŸ¿ã‚’å¼±ã‚ã‚‹ï¼ˆè£œåŠ©çš„ï¼‰
        has_relevant_title = any(keyword in driver.title.lower() for keyword in valid_keywords)
        has_relevant_meta = any(keyword in meta_content for keyword in valid_keywords)

        # ğŸ”¹ ã€æ–°ã—ã„åˆ¤å®šåŸºæº–ã€‘ãƒ•ã‚©ãƒ¼ãƒ ãŒã‚ã‚Šã€ã‹ã¤ãƒ¡ãƒ¼ãƒ«æ¬„ or ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ãŒã‚ã‚‹å ´åˆã¯å•ã„åˆã‚ã›ãƒšãƒ¼ã‚¸ã¨ã™ã‚‹
        if has_form and (has_email_field or has_textarea):
            return True
        
        # ğŸ”¹ ãƒ•ã‚©ãƒ¼ãƒ ãŒãªã„å ´åˆã§ã‚‚ã€URLã‚„ã‚¿ã‚¤ãƒˆãƒ«ã€ãƒ¡ã‚¿æƒ…å ±ã§è£œåŠ©çš„ã«å•ã„åˆã‚ã›ãƒšãƒ¼ã‚¸ã‹åˆ¤æ–­
        if has_form and (has_contact_url or has_relevant_title or has_relevant_meta):
            return True

        return False  # ã©ã®æ¡ä»¶ã‚‚æº€ãŸã•ãªã„å ´åˆã¯å•ã„åˆã‚ã›ãƒšãƒ¼ã‚¸ã§ã¯ãªã„

    except Exception as e:
        logging.error(f"å•ã„åˆã‚ã›ãƒšãƒ¼ã‚¸åˆ¤å®šã‚¨ãƒ©ãƒ¼: {e}")
        return False


def find_contact_page(driver, base_url):
    """å•ã„åˆã‚ã›ãƒšãƒ¼ã‚¸ã‚’æ¤œç´¢ã™ã‚‹"""
    logging.info(f"å•ã„åˆã‚ã›ãƒšãƒ¼ã‚¸æ¤œç´¢é–‹å§‹: {base_url}")

    if not check_scraping_allowed(base_url):
        logging.info(f"ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°NG: {base_url}")
        return {"status": "error", "message": "ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°NG", "contact_page": None}

    try:
        driver.get(base_url)
        time.sleep(5)

        soup = BeautifulSoup(driver.page_source, 'html.parser')

        # 1. ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸å†…ã«ãƒ•ã‚©ãƒ¼ãƒ ãŒã‚ã‚‹ã‹ç¢ºèª
        if is_valid_contact_page(driver):
            logging.info(f"å•ã„åˆã‚ã›ãƒ•ã‚©ãƒ¼ãƒ ã‚’ãƒˆãƒƒãƒ—ãƒšãƒ¼ã‚¸ã§ç™ºè¦‹: {base_url}")

            # ğŸ”¹ å•ã„åˆã‚ã›ãƒšãƒ¼ã‚¸ã«å–¶æ¥­åˆ©ç”¨ç¦æ­¢ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã‚‹ã‹ç¢ºèª
            if contains_sales_restrictions(driver):
                logging.info(f"é€ä»˜ä¸å¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º: {base_url}")
                return {"status": "error", "message": "é€ä»˜ä¸å¯ï¼ˆå–¶æ¥­åˆ©ç”¨ç¦æ­¢ï¼‰", "contact_page": base_url}

            return {"status": "success", "contact_page": base_url}

        # 2. ã€ŒãŠå•ã„åˆã‚ã›ã€ã‚„ã€Œcontactã€ã®ãƒªãƒ³ã‚¯ã‚’æ¢ã—ã¦é·ç§»
        keywords = ["ãŠå•ã„åˆã‚ã›", "ãŠå•åˆã›", "ã‚³ãƒ³ã‚¿ã‚¯ãƒˆ", "contact", "inquiry", "support"]
        links = soup.find_all("a", href=True)

        for link in links:
            link_text = link.get_text(strip=True).lower()
            href = link["href"]

            if any(keyword in link_text for keyword in keywords) or any(keyword in href.lower() for keyword in keywords):
                contact_page = urljoin(base_url.rstrip("/"), href.lstrip("/"))
                logging.info(f"å•ã„åˆã‚ã›ãƒšãƒ¼ã‚¸å€™è£œ: {contact_page}")

                driver.get(contact_page)
                time.sleep(3)

                if is_valid_contact_page(driver):
                    # ğŸ”¹ å•ã„åˆã‚ã›ãƒšãƒ¼ã‚¸ã«å–¶æ¥­åˆ©ç”¨ç¦æ­¢ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã‚‹ã‹ç¢ºèª
                    if contains_sales_restrictions(driver):
                        logging.info(f"é€ä»˜ä¸å¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º: {contact_page}")
                        return {"status": "error", "message": "é€ä»˜ä¸å¯ï¼ˆå–¶æ¥­åˆ©ç”¨ç¦æ­¢ï¼‰", "contact_page": contact_page}

                    logging.info(f"å•ã„åˆã‚ã›ãƒšãƒ¼ã‚¸ç¢ºå®š: {contact_page}")
                    return {"status": "success", "contact_page": contact_page}

    except Exception as e:
        logging.error(f"å•ã„åˆã‚ã›ãƒšãƒ¼ã‚¸æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

    logging.info(f"å•ã„åˆã‚ã›ãƒšãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ: {base_url}")
    return {"status": "error", "message": "å•ã„åˆã‚ã›ãƒšãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ", "contact_page": None}
